{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.alexnet(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of the layer is features.0.weight\n",
      "The parameter associated with this layer is torch.Size([64, 3, 11, 11])\n",
      "\n",
      "The name of the layer is features.0.bias\n",
      "The parameter associated with this layer is torch.Size([64])\n",
      "\n",
      "The name of the layer is features.3.weight\n",
      "The parameter associated with this layer is torch.Size([192, 64, 5, 5])\n",
      "\n",
      "The name of the layer is features.3.bias\n",
      "The parameter associated with this layer is torch.Size([192])\n",
      "\n",
      "The name of the layer is features.6.weight\n",
      "The parameter associated with this layer is torch.Size([384, 192, 3, 3])\n",
      "\n",
      "The name of the layer is features.6.bias\n",
      "The parameter associated with this layer is torch.Size([384])\n",
      "\n",
      "The name of the layer is features.8.weight\n",
      "The parameter associated with this layer is torch.Size([256, 384, 3, 3])\n",
      "\n",
      "The name of the layer is features.8.bias\n",
      "The parameter associated with this layer is torch.Size([256])\n",
      "\n",
      "The name of the layer is features.10.weight\n",
      "The parameter associated with this layer is torch.Size([256, 256, 3, 3])\n",
      "\n",
      "The name of the layer is features.10.bias\n",
      "The parameter associated with this layer is torch.Size([256])\n",
      "\n",
      "The name of the layer is classifier.1.weight\n",
      "The parameter associated with this layer is torch.Size([4096, 9216])\n",
      "\n",
      "The name of the layer is classifier.1.bias\n",
      "The parameter associated with this layer is torch.Size([4096])\n",
      "\n",
      "The name of the layer is classifier.4.weight\n",
      "The parameter associated with this layer is torch.Size([4096, 4096])\n",
      "\n",
      "The name of the layer is classifier.4.bias\n",
      "The parameter associated with this layer is torch.Size([4096])\n",
      "\n",
      "The name of the layer is classifier.6.weight\n",
      "The parameter associated with this layer is torch.Size([1000, 4096])\n",
      "\n",
      "The name of the layer is classifier.6.bias\n",
      "The parameter associated with this layer is torch.Size([1000])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print (\"The name of the layer is\", name)\n",
    "    print (\"The parameter associated with this layer is\", param.size())\n",
    "    print ()\n",
    "#     if(i != 0):\n",
    "#         continue\n",
    "#     else:\n",
    "#         #print (\"This parameter is\", param)\n",
    "#         print (type(param))\n",
    "#         print (param.size())\n",
    "#         #print (\"This is the test\", param.data)\n",
    "#         print (type(param.data))\n",
    "#         print (param.data.size())\n",
    "#         i = i+1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x7fa4cd7d2ac8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tea = torch.randn((8, 32))\n",
    "coffee = torch.randn((8, 32))\n",
    "temp_dict = {}\n",
    "\n",
    "temp_dict[\"tea\"] = tea\n",
    "temp_dict[\"coffee\"] = coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dict.get(\"tea\") == temp_dict[\"tea\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tea': tensor([[ 1.7375e+00,  1.4215e+00,  1.6562e+00, -6.0398e-01, -2.1572e+00,\n",
       "          -1.9815e+00, -7.7471e-01, -5.5244e-01, -1.0802e+00, -4.5980e-01,\n",
       "          -1.0572e+00,  4.2822e-01,  3.6593e-01, -1.0045e+00, -8.4732e-01,\n",
       "           1.6744e+00,  1.7012e+00, -7.2895e-01, -5.3089e-02, -5.2130e-01,\n",
       "           2.3103e-01, -4.6973e-01, -7.4200e-01, -2.8452e-01, -2.2379e-01,\n",
       "           4.5974e-01,  7.2097e-02,  1.9791e-01,  2.0499e+00,  3.8889e-01,\n",
       "          -9.8687e-01, -1.0467e+00],\n",
       "         [ 9.2609e-02,  6.1942e-01, -2.2207e-01,  8.6739e-01,  2.6532e+00,\n",
       "           9.9115e-01, -1.7815e-01,  1.4214e-02,  4.5556e-01,  2.6646e-01,\n",
       "           6.8671e-02,  2.9556e-01,  7.9176e-01,  6.6480e-01, -2.9537e-01,\n",
       "           3.4447e-01, -6.5939e-01,  1.3807e+00, -4.6402e-01,  2.4313e+00,\n",
       "           1.4861e+00,  1.0283e+00, -3.4517e-01, -3.6580e-01,  1.7335e+00,\n",
       "           3.7072e-02,  6.6314e-01, -4.9133e-01,  5.2561e-01,  2.9247e-02,\n",
       "          -1.9349e-01, -1.9132e+00],\n",
       "         [ 1.2169e+00, -1.1178e+00,  2.7056e-03,  1.6643e+00, -1.0574e+00,\n",
       "           4.5129e-01, -1.5069e+00, -1.0492e+00,  1.1687e+00, -1.4799e+00,\n",
       "          -6.5573e-01, -1.3220e+00,  5.5395e-01,  2.6665e-01,  1.1906e+00,\n",
       "           2.3398e-01,  2.5064e+00, -4.1628e-01,  1.4538e+00,  4.1554e-01,\n",
       "          -2.1393e+00,  4.6683e-01, -2.6964e-01,  4.2248e-01,  4.9619e-01,\n",
       "           7.0996e-01, -3.5606e-01, -8.4558e-01,  1.3691e+00,  1.4424e+00,\n",
       "          -1.0682e+00,  1.2175e+00],\n",
       "         [-1.5509e-01,  3.3772e-01, -2.4139e-01, -2.4490e-01, -1.9047e-02,\n",
       "           8.9086e-01,  1.0349e-01,  1.2825e+00,  1.2537e-01, -1.4600e+00,\n",
       "           4.5493e-01, -7.2545e-01, -6.0192e-02, -2.6457e-01, -8.6968e-01,\n",
       "           5.3549e-01, -2.8095e-01, -8.9706e-01,  1.1812e+00, -7.6361e-01,\n",
       "          -1.4998e-01, -1.2707e-01, -7.5573e-01,  2.8290e+00, -2.2300e-01,\n",
       "           4.7919e-01,  7.4690e-02,  1.6345e-01, -4.7617e-02, -1.2660e+00,\n",
       "           5.8958e-02, -3.4278e+00],\n",
       "         [-1.6537e+00, -1.8989e-01, -1.6910e-01,  1.1664e+00,  7.3187e-01,\n",
       "           1.3143e+00,  6.3171e-01,  3.5522e-01,  6.8641e-01,  9.6112e-01,\n",
       "          -1.2173e+00, -1.1481e-01,  7.6880e-01, -1.4644e+00, -2.4945e+00,\n",
       "          -3.7127e-01, -3.0923e-01, -2.2443e-01, -2.1568e-01,  1.5694e+00,\n",
       "           4.3859e-01, -2.9543e-03, -1.7367e+00,  2.1754e-02, -2.7685e-01,\n",
       "          -4.2407e-03,  4.6077e-02, -2.4838e+00,  1.2139e+00,  8.4106e-01,\n",
       "           1.6449e+00,  1.7600e-01],\n",
       "         [ 5.6837e-01,  2.7044e-01, -1.0140e+00,  8.3834e-01,  1.0772e+00,\n",
       "          -9.5113e-01, -1.9530e+00,  3.6742e-01, -8.4994e-01,  7.8092e-02,\n",
       "          -2.3258e-01, -1.0304e-01,  8.6087e-02, -9.6637e-01,  3.6021e-01,\n",
       "           6.5516e-01, -8.7504e-01, -3.0264e-02, -4.7702e-02,  1.7531e+00,\n",
       "          -8.0681e-01, -6.4677e-01,  2.3344e-01, -8.5278e-01,  5.8807e-01,\n",
       "           7.1239e-01,  1.1025e-01, -2.6924e-01, -1.8541e+00,  5.7476e-01,\n",
       "           9.6543e-02, -1.0409e+00],\n",
       "         [-1.4771e+00, -1.0526e+00,  6.6220e-01,  1.0928e+00, -1.0273e+00,\n",
       "          -3.6817e-01, -1.9268e-01, -4.3005e-01,  1.0964e-01,  1.4254e+00,\n",
       "           8.3461e-01,  1.7537e+00, -1.5343e+00, -9.5291e-01, -1.6796e+00,\n",
       "           5.5293e-01, -1.3087e+00,  6.7414e-01, -7.4101e-01, -1.8624e-01,\n",
       "          -1.9685e-01, -1.5093e-02,  1.5409e+00, -2.6303e-01,  8.6265e-01,\n",
       "          -2.9548e-01, -1.7565e+00, -1.0067e-01, -4.2805e-01, -1.4275e+00,\n",
       "          -3.1486e-01, -1.0208e+00],\n",
       "         [-5.3905e-01, -1.9271e-01,  1.6375e-01, -4.7543e-02,  9.9942e-01,\n",
       "           5.5285e-02, -5.0521e-01, -6.1304e-01,  2.7315e-01,  5.2907e-01,\n",
       "          -7.7283e-01, -1.7393e-01,  2.1370e+00, -1.0943e+00, -1.2981e+00,\n",
       "          -1.9551e+00, -2.2897e-01,  8.7391e-02,  2.5198e+00, -2.1399e-01,\n",
       "           2.7304e-01,  1.9718e+00, -8.1039e-01,  3.0029e-01,  1.7144e+00,\n",
       "          -1.7217e+00,  5.2771e-01, -2.3298e+00,  9.7995e-01,  1.9451e-01,\n",
       "          -4.8393e-01,  6.1117e-01]]),\n",
       " 'coffee': tensor([[ 0.6321,  0.4213, -0.1898,  1.4559,  1.9967, -0.7857, -0.7709,  0.1760,\n",
       "           0.2307, -0.8126, -0.5220, -0.2213, -0.2098, -1.1296,  0.6231, -0.1726,\n",
       "           0.0597,  2.6723,  0.4235, -0.1451,  0.7086, -0.4739, -1.3593, -1.0487,\n",
       "          -0.6806,  1.5593, -0.3617, -0.9877, -0.2722, -2.4197,  0.2689,  0.8957],\n",
       "         [-1.0219, -1.4996,  0.0103, -1.3625,  2.6051,  0.1331, -0.5611,  0.4117,\n",
       "           0.3958, -0.4603, -0.4648,  1.2427,  0.0445,  0.2409, -0.9151,  0.1851,\n",
       "          -0.0860, -0.1104,  2.8317,  0.4736, -0.6291, -0.0572, -1.1354, -0.0494,\n",
       "          -1.2359,  1.4079, -0.3911,  0.3453, -0.7568,  0.3606,  0.4414,  1.0835],\n",
       "         [ 2.2285, -1.7757,  0.3932, -1.3198,  1.1061, -0.2290,  0.6216,  1.6074,\n",
       "          -0.0600, -1.2882,  0.1699, -1.0972, -0.6899, -0.6431,  0.3376,  0.3941,\n",
       "           0.5189, -2.4350,  1.4807, -0.9766,  0.5028,  0.8668, -0.6382, -0.7913,\n",
       "           0.6488,  1.3105,  0.1423, -0.5127, -0.6174, -0.3214,  0.1103,  0.8653],\n",
       "         [-0.4047,  1.0874,  0.4642, -0.3273,  2.0566, -0.2855, -1.8270,  0.9037,\n",
       "           0.7789, -1.4563,  0.0160,  1.0782,  0.3957,  0.5271,  0.6830,  0.6670,\n",
       "          -0.7589,  0.7926,  0.8704, -1.2770,  0.3619, -0.5777, -0.6702,  0.4025,\n",
       "          -0.9253, -0.2756, -0.3747,  0.5769, -0.4460, -2.1255,  0.0082, -0.1147],\n",
       "         [-0.8836, -1.4928, -1.6607, -0.4414,  0.0192,  0.4962,  0.3037,  0.6394,\n",
       "          -1.4227,  1.3239,  1.1148,  0.0646, -0.1643,  0.0158, -0.7784, -1.1985,\n",
       "          -0.7087,  0.9524,  2.1686, -1.7300,  1.2234, -1.6105,  1.0201, -0.8330,\n",
       "          -0.4586,  0.0440,  0.9575, -2.1163,  0.2995,  0.6486,  0.1961,  0.1366],\n",
       "         [-0.7578, -2.3015,  0.0903, -1.3742, -0.8498,  0.7420, -0.0448,  2.0955,\n",
       "          -1.6517, -0.0781, -0.0896,  0.5493, -1.6651, -0.6029, -1.5314,  0.5359,\n",
       "           0.2231, -0.2957,  1.2362,  1.6786, -1.0162, -2.4131, -0.7399, -0.4680,\n",
       "           0.3049, -0.1189,  0.2422, -0.3735,  1.2933, -0.8661, -1.9830, -0.9898],\n",
       "         [-1.4936, -0.3664,  0.4727,  0.5896,  0.5732,  0.6660,  0.7497,  1.0441,\n",
       "          -0.2280, -0.8471, -0.0891,  0.2141,  0.7137, -0.3949,  0.9677, -1.0557,\n",
       "           0.1244,  0.8244, -0.6081, -0.2680,  1.7607, -2.8784, -0.8539, -0.5007,\n",
       "           2.6344,  0.0145, -1.2573, -1.8909,  0.2651,  0.7120,  0.5079,  0.0299],\n",
       "         [ 1.8800, -0.7252,  0.0498,  0.6855,  1.4980,  1.0617, -0.7713, -0.7873,\n",
       "           1.2051,  1.9175,  1.2564, -1.4204, -1.1328, -1.1271,  0.6959,  1.5441,\n",
       "           0.8227, -0.4441, -0.7809,  0.3949, -0.7967,  2.5945, -0.8439,  0.2801,\n",
       "           0.0251, -0.1981, -1.8522,  0.7955,  1.0663, -0.1805,  1.1801, -0.5283]])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = optim.SGD(model.parameters(), lr = 0.001, weight_decay = 0, momentum = 0.9, nesterov = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in b.param_groups:\n",
    "    param = group['params']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found tea\n",
      "Found coffee\n",
      "Could not find fedora\n"
     ]
    }
   ],
   "source": [
    "keys = [\"tea\", \"coffee\", \"fedora\"]\n",
    "\n",
    "for item in keys:\n",
    "    if item in temp_dict:\n",
    "        print (\"Found\", item)\n",
    "    else:\n",
    "        print (\"Could not find\", item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'hymenoptera_data'\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7fa4c615d828>,\n",
       " 'val': <torch.utils.data.dataloader.DataLoader at 0x7fa4c615db00>}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn((2,4))\n",
    "b = torch.randn((2,4))\n",
    "c = torch.mul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3786,  0.0440, -0.2838,  1.3714],\n",
       "        [-0.0076, -0.1488,  0.7654,  1.7603]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7102,  1.1513, -1.1188, -2.2216],\n",
       "        [ 0.0081,  0.2964,  0.7646,  2.0896]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5330,  0.0382,  0.2536, -0.6173],\n",
       "        [-0.9389, -0.5022,  1.0011,  0.8424]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004\n"
     ]
    }
   ],
   "source": [
    "current_size = 250\n",
    "print (1/float(current_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "The size of the batch index is 4\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for data in dataloaders['train']:\n",
    "    inputs, labels = data\n",
    "    print(\"The size of the batch index is\", inputs.size(0))\n",
    "    index = index + 1\n",
    "    curr_size = (batch_index+1)*batch_size\n",
    "print (index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
